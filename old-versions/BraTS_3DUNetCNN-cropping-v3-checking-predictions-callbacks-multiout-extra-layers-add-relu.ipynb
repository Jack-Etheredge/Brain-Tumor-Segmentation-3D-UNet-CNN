{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing memory load:\n",
    "- crop images\n",
    "- reduce batch size\n",
    "- reduce number of channels (have 4 available)\n",
    "- reduce number of base filters\n",
    "- reduce depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working configurations:\n",
    "\n",
    "#### single channel cropped beyond zeros, batch size 1, depth 4, number of base filters 16:\n",
    "depth = 4  \n",
    "filter_num = 16  \n",
    "model = isensee2017_model(input_shape=(1, 144,144,144), n_base_filters=filter_num, depth=depth, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")\n",
    "\n",
    "#### 4-channel cropped beyond zeros, batch size 1, depth 4, number of base filters 16:\n",
    "depth = 4  \n",
    "filter_num = 16  \n",
    "model = isensee2017_model(input_shape=(4, 144,144,144), n_base_filters=filter_num, depth=depth, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")                      \n",
    "\n",
    "#### 4-channel cropped full size, batch size 1, depth 4, number of base filters 8:\n",
    "model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=8, depth=4, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")\n",
    "\n",
    "#### 4-channel cropped full size, batch size 1, depth 5, number of base filters 8:\n",
    "model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=8, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")\n",
    "\n",
    "#### 4-channel cropped full size, batch size 1, depth 5, number of base filters 12:\n",
    "model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=16, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")\n",
    "\n",
    "#### 4-channel cropped full size, batch size 2, depth 5, number of base filters 6:\n",
    "model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=6, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")\n",
    "\n",
    "### out of memory configurations:\n",
    "#### 4-channel cropped full size, batch size 1, depth 5, number of base filters 16:\n",
    "model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=16, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")\n",
    "                      \n",
    "#### 4-channel cropped full size, batch size 2, depth 5, number of base filters 12:\n",
    "model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=12, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function=weighted_dice_coefficient_loss, activation_name=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:37:19.755506Z",
     "start_time": "2018-06-19T23:37:17.107613Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "from keras.layers import Input, LeakyReLU, Add, UpSampling3D, Activation, SpatialDropout3D\n",
    "from keras.engine import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Deconvolution3D, Flatten, Dense, GlobalAveragePooling3D\n",
    "\n",
    "# K.set_image_dim_ordering('th')\n",
    "K.set_image_dim_ordering('tf')\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "try:\n",
    "    from keras.engine import merge\n",
    "except ImportError:\n",
    "    from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in survival data.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:37:19.778795Z",
     "start_time": "2018-06-19T23:37:19.757500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survival_data = pd.read_csv('survival_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:40:16.711845Z",
     "start_time": "2018-06-19T23:40:16.706597Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = 'Brats17_TCIA_469_1'\n",
    "survival_data[survival_data.Brats17ID==ID].Survival.astype(int).values.item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return -dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def weighted_dice_coefficient(y_true, y_pred, axis=(-3, -2, -1), smooth=0.00001):\n",
    "    \"\"\"\n",
    "    Weighted dice coefficient. Default axis assumes a \"channels first\" data structure\n",
    "    :param smooth:\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :param axis:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return K.mean(2. * (K.sum(y_true * y_pred,\n",
    "                              axis=axis) + smooth/2)/(K.sum(y_true,\n",
    "                                                            axis=axis) + K.sum(y_pred,\n",
    "                                                                               axis=axis) + smooth))\n",
    "\n",
    "\n",
    "def weighted_dice_coefficient_loss(y_true, y_pred):\n",
    "    return -weighted_dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def label_wise_dice_coefficient(y_true, y_pred, label_index):\n",
    "    return dice_coefficient(y_true[:, label_index], y_pred[:, label_index])\n",
    "\n",
    "\n",
    "def get_label_dice_coefficient_function(label_index):\n",
    "    f = partial(label_wise_dice_coefficient, label_index=label_index)\n",
    "    f.__setattr__('__name__', 'label_{0}_dice_coef'.format(label_index))\n",
    "    return f\n",
    "\n",
    "\n",
    "dice_coef = dice_coefficient\n",
    "dice_coef_loss = dice_coefficient_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T15:26:01.192753Z",
     "start_time": "2018-06-16T15:25:59.659294Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_convolution_block(input_layer, n_filters, batch_normalization=False, kernel=(3, 3, 3), activation=None,\n",
    "                             padding='same', strides=(1, 1, 1), instance_normalization=False):\n",
    "    \"\"\"\n",
    "    :param strides:\n",
    "    :param input_layer:\n",
    "    :param n_filters:\n",
    "    :param batch_normalization:\n",
    "    :param kernel:\n",
    "    :param activation: Keras activation layer to use. (default is 'relu')\n",
    "    :param padding:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(input_layer)\n",
    "    if batch_normalization:\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "    elif instance_normalization:\n",
    "        try:\n",
    "            from keras_contrib.layers.normalization import InstanceNormalization\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Install keras_contrib in order to use instance normalization.\"\n",
    "                              \"\\nTry: pip install git+https://www.github.com/farizrahman4u/keras-contrib.git\")\n",
    "        layer = InstanceNormalization(axis=1)(layer)\n",
    "    if activation is None:\n",
    "        return Activation('relu')(layer)\n",
    "    else:\n",
    "        return activation()(layer)\n",
    "\n",
    "\n",
    "def compute_level_output_shape(n_filters, depth, pool_size, image_shape):\n",
    "    \"\"\"\n",
    "    Each level has a particular output shape based on the number of filters used in that level and the depth or number \n",
    "    of max pooling operations that have been done on the data at that point.\n",
    "    :param image_shape: shape of the 3d image.\n",
    "    :param pool_size: the pool_size parameter used in the max pooling operation.\n",
    "    :param n_filters: Number of filters used by the last node in a given level.\n",
    "    :param depth: The number of levels down in the U-shaped model a given node is.\n",
    "    :return: 5D vector of the shape of the output node \n",
    "    \"\"\"\n",
    "    output_image_shape = np.asarray(np.divide(image_shape, np.power(pool_size, depth)), dtype=np.int32).tolist()\n",
    "    return tuple([None, n_filters] + output_image_shape)\n",
    "\n",
    "\n",
    "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                       deconvolution=False):\n",
    "    if deconvolution:\n",
    "        return Deconvolution3D(filters=n_filters, kernel_size=kernel_size,\n",
    "                               strides=strides)\n",
    "    else:\n",
    "        return UpSampling3D(size=pool_size)\n",
    "\n",
    "def create_localization_module(input_layer, n_filters):\n",
    "    convolution1 = create_convolution_block(input_layer, n_filters)\n",
    "    convolution2 = create_convolution_block(convolution1, n_filters, kernel=(1, 1, 1))\n",
    "    return convolution2\n",
    "\n",
    "\n",
    "def create_up_sampling_module(input_layer, n_filters, size=(2, 2, 2)):\n",
    "    up_sample = UpSampling3D(size=size)(input_layer)\n",
    "    convolution = create_convolution_block(up_sample, n_filters)\n",
    "    return convolution\n",
    "\n",
    "\n",
    "def create_context_module(input_layer, n_level_filters, dropout_rate=0.3, data_format=\"channels_first\"):\n",
    "    convolution1 = create_convolution_block(input_layer=input_layer, n_filters=n_level_filters)\n",
    "    dropout = SpatialDropout3D(rate=dropout_rate, data_format=data_format)(convolution1)\n",
    "    convolution2 = create_convolution_block(input_layer=dropout, n_filters=n_level_filters)\n",
    "    return convolution2\n",
    "\n",
    "\n",
    "create_convolution_block = partial(create_convolution_block, activation=LeakyReLU, instance_normalization=True)\n",
    "\n",
    "\n",
    "def isensee2017_model(input_shape=(4, 128, 128, 128), n_base_filters=16, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=4, optimizer=Adam, initial_learning_rate=5e-4,\n",
    "                      loss_function={'activation_block': weighted_dice_coefficient_loss, 'survival_block': 'mean_squared_error'}, \n",
    "                      activation_name=\"sigmoid\"):\n",
    "    \"\"\"\n",
    "    This function builds a model proposed by Isensee et al. for the BRATS 2017 competition:\n",
    "    https://www.cbica.upenn.edu/sbia/Spyridon.Bakas/MICCAI_BraTS/MICCAI_BraTS_2017_proceedings_shortPapers.pdf\n",
    "    This network is highly similar to the model proposed by Kayalibay et al. \"CNN-based Segmentation of Medical\n",
    "    Imaging Data\", 2017: https://arxiv.org/pdf/1701.03056.pdf\n",
    "    :param input_shape:\n",
    "    :param n_base_filters:\n",
    "    :param depth:\n",
    "    :param dropout_rate:\n",
    "    :param n_segmentation_levels:\n",
    "    :param n_labels:\n",
    "    :param optimizer:\n",
    "    :param initial_learning_rate:\n",
    "    :param loss_function:\n",
    "    :param activation_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    current_layer = inputs\n",
    "    level_output_layers = list()\n",
    "    level_filters = list()\n",
    "    for level_number in range(depth):\n",
    "        n_level_filters = (2**level_number) * n_base_filters\n",
    "        level_filters.append(n_level_filters)\n",
    "\n",
    "        if current_layer is inputs:\n",
    "            in_conv = create_convolution_block(current_layer, n_level_filters)\n",
    "        else:\n",
    "            in_conv = create_convolution_block(current_layer, n_level_filters, strides=(2, 2, 2))\n",
    "\n",
    "        context_output_layer = create_context_module(in_conv, n_level_filters, dropout_rate=dropout_rate)\n",
    "\n",
    "        summation_layer = Add()([in_conv, context_output_layer])\n",
    "        level_output_layers.append(summation_layer)\n",
    "        current_layer = summation_layer\n",
    "\n",
    "    segmentation_layers = list()\n",
    "    for level_number in range(depth - 2, -1, -1):\n",
    "        up_sampling = create_up_sampling_module(current_layer, level_filters[level_number])\n",
    "        concatenation_layer = concatenate([level_output_layers[level_number], up_sampling], axis=1)\n",
    "        localization_output = create_localization_module(concatenation_layer, level_filters[level_number])\n",
    "        current_layer = localization_output\n",
    "        if level_number < n_segmentation_levels:\n",
    "            segmentation_layers.insert(0, create_convolution_block(current_layer, n_filters=n_labels, kernel=(1, 1, 1)))\n",
    "\n",
    "    output_layer = None\n",
    "    for level_number in reversed(range(n_segmentation_levels)):\n",
    "        segmentation_layer = segmentation_layers[level_number]\n",
    "        if output_layer is None:\n",
    "            output_layer = segmentation_layer\n",
    "        else:\n",
    "            output_layer = Add()([output_layer, segmentation_layer])\n",
    "\n",
    "        if level_number > 0:\n",
    "            output_layer = UpSampling3D(size=(2, 2, 2))(output_layer)\n",
    "\n",
    "    activation_block = Activation(activation = activation_name, name='activation_block')(output_layer)\n",
    "#     survival_block = Activation(\"linear\")(summation_layer)\n",
    "#     activation_block = Dense(1, activation=activation_name, name='activation_block')(output_layer)\n",
    "#     flatten = Flatten(name='flatten')(summation_layer)\n",
    "#     survival_block = Dense(1, activation='linear', name='survival_block')(flatten)\n",
    "    \n",
    "    survival_conv_1 = Conv3D(activation='relu', filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='survival_conv_1')(summation_layer)\n",
    "    survival_conv_2 = Conv3D(activation='relu', filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='survival_conv_2')(survival_conv_1)\n",
    "    dropout = SpatialDropout3D(rate=dropout_rate, data_format='channels_first', name='dropout')(survival_conv_2)\n",
    "    survival_conv_3 = Conv3D(activation='relu', filters=n_level_filters, kernel_size=(3, 3, 3), padding='same', strides=(1, 1, 1), name='survival_conv_3')(dropout)\n",
    "    survival_GAP = GlobalAveragePooling3D(name='survival_GAP')(survival_conv_3)\n",
    "#     flatten = Flatten(name='flatten')(survival_GAP)\n",
    "#     survival_block = Activation(\"linear\", name='survival_block')(flatten)\n",
    "    survival_block = Dense(1, activation='linear', name='survival_block')(survival_GAP)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[activation_block,survival_block])\n",
    "#     model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function)\n",
    "    model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function, \n",
    "                  loss_weights={'activation_block': 1., 'survival_block': 0.2},\n",
    "                 metrics={'activation_block': ['accuracy',weighted_dice_coefficient, dice_coefficient], 'survival_block': ['accuracy']})\n",
    "#     loss={'activation_block': 'binary_crossentropy', 'survival_block': 'mean_squared_error'}\n",
    "    # assign weights and loss as dictionaries\n",
    "    # functional-api-guide\n",
    "    # loss_weights define the ratio of how much I care about optimizing each one\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:15:08.191305Z",
     "start_time": "2018-06-16T16:15:07.066321Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_1 (InputLayer)                             (None, 4, 160, 192, 160)         0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)                                (None, 12, 160, 192, 160)        1308              input_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_1 (InstanceNormalization) (None, 12, 160, 192, 160)        24                conv3d_1[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)                        (None, 12, 160, 192, 160)        0                 instance_normalization_1[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)                                (None, 12, 160, 192, 160)        3900              leaky_re_lu_1[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_2 (InstanceNormalization) (None, 12, 160, 192, 160)        24                conv3d_2[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)                        (None, 12, 160, 192, 160)        0                 instance_normalization_2[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "spatial_dropout3d_1 (SpatialDropout3D)           (None, 12, 160, 192, 160)        0                 leaky_re_lu_2[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)                                (None, 12, 160, 192, 160)        3900              spatial_dropout3d_1[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_3 (InstanceNormalization) (None, 12, 160, 192, 160)        24                conv3d_3[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)                        (None, 12, 160, 192, 160)        0                 instance_normalization_3[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_1 (Add)                                      (None, 12, 160, 192, 160)        0                 leaky_re_lu_1[0][0]                               \n",
      "                                                                                                    leaky_re_lu_3[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)                                (None, 24, 80, 96, 80)           7800              add_1[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_4 (InstanceNormalization) (None, 24, 80, 96, 80)           48                conv3d_4[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)                        (None, 24, 80, 96, 80)           0                 instance_normalization_4[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)                                (None, 24, 80, 96, 80)           15576             leaky_re_lu_4[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_5 (InstanceNormalization) (None, 24, 80, 96, 80)           48                conv3d_5[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)                        (None, 24, 80, 96, 80)           0                 instance_normalization_5[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "spatial_dropout3d_2 (SpatialDropout3D)           (None, 24, 80, 96, 80)           0                 leaky_re_lu_5[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)                                (None, 24, 80, 96, 80)           15576             spatial_dropout3d_2[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_6 (InstanceNormalization) (None, 24, 80, 96, 80)           48                conv3d_6[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)                        (None, 24, 80, 96, 80)           0                 instance_normalization_6[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_2 (Add)                                      (None, 24, 80, 96, 80)           0                 leaky_re_lu_4[0][0]                               \n",
      "                                                                                                    leaky_re_lu_6[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)                                (None, 48, 40, 48, 40)           31152             add_2[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_7 (InstanceNormalization) (None, 48, 40, 48, 40)           96                conv3d_7[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)                        (None, 48, 40, 48, 40)           0                 instance_normalization_7[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)                                (None, 48, 40, 48, 40)           62256             leaky_re_lu_7[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_8 (InstanceNormalization) (None, 48, 40, 48, 40)           96                conv3d_8[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)                        (None, 48, 40, 48, 40)           0                 instance_normalization_8[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "spatial_dropout3d_3 (SpatialDropout3D)           (None, 48, 40, 48, 40)           0                 leaky_re_lu_8[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)                                (None, 48, 40, 48, 40)           62256             spatial_dropout3d_3[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_9 (InstanceNormalization) (None, 48, 40, 48, 40)           96                conv3d_9[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)                        (None, 48, 40, 48, 40)           0                 instance_normalization_9[0][0]                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_3 (Add)                                      (None, 48, 40, 48, 40)           0                 leaky_re_lu_7[0][0]                               \n",
      "                                                                                                    leaky_re_lu_9[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)                               (None, 96, 20, 24, 20)           124512            add_3[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_10 (InstanceNormalization (None, 96, 20, 24, 20)           192               conv3d_10[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)                       (None, 96, 20, 24, 20)           0                 instance_normalization_10[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)                               (None, 96, 20, 24, 20)           248928            leaky_re_lu_10[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_11 (InstanceNormalization (None, 96, 20, 24, 20)           192               conv3d_11[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)                       (None, 96, 20, 24, 20)           0                 instance_normalization_11[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "spatial_dropout3d_4 (SpatialDropout3D)           (None, 96, 20, 24, 20)           0                 leaky_re_lu_11[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)                               (None, 96, 20, 24, 20)           248928            spatial_dropout3d_4[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_12 (InstanceNormalization (None, 96, 20, 24, 20)           192               conv3d_12[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)                       (None, 96, 20, 24, 20)           0                 instance_normalization_12[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_4 (Add)                                      (None, 96, 20, 24, 20)           0                 leaky_re_lu_10[0][0]                              \n",
      "                                                                                                    leaky_re_lu_12[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)                               (None, 192, 10, 12, 10)          497856            add_4[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_13 (InstanceNormalization (None, 192, 10, 12, 10)          384               conv3d_13[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)                       (None, 192, 10, 12, 10)          0                 instance_normalization_13[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)                               (None, 192, 10, 12, 10)          995520            leaky_re_lu_13[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_14 (InstanceNormalization (None, 192, 10, 12, 10)          384               conv3d_14[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)                       (None, 192, 10, 12, 10)          0                 instance_normalization_14[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "spatial_dropout3d_5 (SpatialDropout3D)           (None, 192, 10, 12, 10)          0                 leaky_re_lu_14[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)                               (None, 192, 10, 12, 10)          995520            spatial_dropout3d_5[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_15 (InstanceNormalization (None, 192, 10, 12, 10)          384               conv3d_15[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)                       (None, 192, 10, 12, 10)          0                 instance_normalization_15[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_5 (Add)                                      (None, 192, 10, 12, 10)          0                 leaky_re_lu_13[0][0]                              \n",
      "                                                                                                    leaky_re_lu_15[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)                   (None, 192, 20, 24, 20)          0                 add_5[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)                               (None, 96, 20, 24, 20)           497760            up_sampling3d_1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_16 (InstanceNormalization (None, 96, 20, 24, 20)           192               conv3d_16[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)                       (None, 96, 20, 24, 20)           0                 instance_normalization_16[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)                      (None, 192, 20, 24, 20)          0                 add_4[0][0]                                       \n",
      "                                                                                                    leaky_re_lu_16[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)                               (None, 96, 20, 24, 20)           497760            concatenate_1[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_17 (InstanceNormalization (None, 96, 20, 24, 20)           192               conv3d_17[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)                       (None, 96, 20, 24, 20)           0                 instance_normalization_17[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)                               (None, 96, 20, 24, 20)           9312              leaky_re_lu_17[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_18 (InstanceNormalization (None, 96, 20, 24, 20)           192               conv3d_18[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)                       (None, 96, 20, 24, 20)           0                 instance_normalization_18[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)                   (None, 96, 40, 48, 40)           0                 leaky_re_lu_18[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)                               (None, 48, 40, 48, 40)           124464            up_sampling3d_2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_19 (InstanceNormalization (None, 48, 40, 48, 40)           96                conv3d_19[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)                       (None, 48, 40, 48, 40)           0                 instance_normalization_19[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)                      (None, 96, 40, 48, 40)           0                 add_3[0][0]                                       \n",
      "                                                                                                    leaky_re_lu_19[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)                               (None, 48, 40, 48, 40)           124464            concatenate_2[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_20 (InstanceNormalization (None, 48, 40, 48, 40)           96                conv3d_20[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)                       (None, 48, 40, 48, 40)           0                 instance_normalization_20[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)                               (None, 48, 40, 48, 40)           2352              leaky_re_lu_20[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_21 (InstanceNormalization (None, 48, 40, 48, 40)           96                conv3d_21[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)                       (None, 48, 40, 48, 40)           0                 instance_normalization_21[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)                   (None, 48, 80, 96, 80)           0                 leaky_re_lu_21[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)                               (None, 24, 80, 96, 80)           31128             up_sampling3d_3[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_23 (InstanceNormalization (None, 24, 80, 96, 80)           48                conv3d_23[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)                       (None, 24, 80, 96, 80)           0                 instance_normalization_23[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)                      (None, 48, 80, 96, 80)           0                 add_2[0][0]                                       \n",
      "                                                                                                    leaky_re_lu_23[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)                               (None, 24, 80, 96, 80)           31128             concatenate_3[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_24 (InstanceNormalization (None, 24, 80, 96, 80)           48                conv3d_24[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)                       (None, 24, 80, 96, 80)           0                 instance_normalization_24[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)                               (None, 24, 80, 96, 80)           600               leaky_re_lu_24[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_25 (InstanceNormalization (None, 24, 80, 96, 80)           48                conv3d_25[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)                       (None, 24, 80, 96, 80)           0                 instance_normalization_25[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_4 (UpSampling3D)                   (None, 24, 160, 192, 160)        0                 leaky_re_lu_25[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)                               (None, 12, 160, 192, 160)        7788              up_sampling3d_4[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_27 (InstanceNormalization (None, 12, 160, 192, 160)        24                conv3d_27[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)                       (None, 12, 160, 192, 160)        0                 instance_normalization_27[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)                      (None, 24, 160, 192, 160)        0                 add_1[0][0]                                       \n",
      "                                                                                                    leaky_re_lu_27[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)                               (None, 12, 160, 192, 160)        7788              concatenate_4[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_28 (InstanceNormalization (None, 12, 160, 192, 160)        24                conv3d_28[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)                       (None, 12, 160, 192, 160)        0                 instance_normalization_28[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)                               (None, 3, 40, 48, 40)            147               leaky_re_lu_21[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)                               (None, 12, 160, 192, 160)        156               leaky_re_lu_28[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_22 (InstanceNormalization (None, 3, 40, 48, 40)            6                 conv3d_22[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)                               (None, 3, 80, 96, 80)            75                leaky_re_lu_25[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_29 (InstanceNormalization (None, 12, 160, 192, 160)        24                conv3d_29[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)                       (None, 3, 40, 48, 40)            0                 instance_normalization_22[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_26 (InstanceNormalization (None, 3, 80, 96, 80)            6                 conv3d_26[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)                       (None, 12, 160, 192, 160)        0                 instance_normalization_29[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "survival_conv_1 (Conv3D)                         (None, 192, 10, 12, 10)          995520            add_5[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_5 (UpSampling3D)                   (None, 3, 80, 96, 80)            0                 leaky_re_lu_22[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)                       (None, 3, 80, 96, 80)            0                 instance_normalization_26[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)                               (None, 3, 160, 192, 160)         39                leaky_re_lu_29[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "survival_conv_2 (Conv3D)                         (None, 192, 10, 12, 10)          995520            survival_conv_1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_6 (Add)                                      (None, 3, 80, 96, 80)            0                 up_sampling3d_5[0][0]                             \n",
      "                                                                                                    leaky_re_lu_26[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "instance_normalization_30 (InstanceNormalization (None, 3, 160, 192, 160)         6                 conv3d_30[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout (SpatialDropout3D)                       (None, 192, 10, 12, 10)          0                 survival_conv_2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_6 (UpSampling3D)                   (None, 3, 160, 192, 160)         0                 add_6[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)                       (None, 3, 160, 192, 160)         0                 instance_normalization_30[0][0]                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "survival_conv_3 (Conv3D)                         (None, 192, 10, 12, 10)          995520            dropout[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_7 (Add)                                      (None, 3, 160, 192, 160)         0                 up_sampling3d_6[0][0]                             \n",
      "                                                                                                    leaky_re_lu_30[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "survival_GAP (GlobalAveragePooling3D)            (None, 192)                      0                 survival_conv_3[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_block (Activation)                    (None, 3, 160, 192, 160)         0                 add_7[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "survival_block (Dense)                           (None, 1)                        193               survival_GAP[0][0]                                \n",
      "======================================================================================================================================================\n",
      "Total params: 7,640,032\n",
      "Trainable params: 7,640,032\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# change the number of labels?\n",
    "# loss_function={'activation_block': weighted_dice_coefficient_loss, 'survival_block': 'mean_squared_error'}\n",
    "\n",
    "model = isensee2017_model(input_shape=(4, 160, 192, 160), n_base_filters=12, depth=5, dropout_rate=0.3,\n",
    "                      n_segmentation_levels=3, n_labels=3, optimizer=RMSprop, initial_learning_rate=5e-4,\n",
    "                      loss_function={'activation_block': weighted_dice_coefficient_loss, 'survival_block': 'mean_squared_error'}, \n",
    "                          activation_name=\"sigmoid\")\n",
    "model.summary(line_length=150) # add the parameter that allows me to show everything instead of cutting it off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T20:10:10.456092Z",
     "start_time": "2018-06-15T20:10:10.453503Z"
    }
   },
   "source": [
    "## Make the labels and test train dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T21:07:14.833644Z",
     "start_time": "2018-06-19T21:07:14.826791Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "# from glob import glob\n",
    "# paths = glob('/Users/etheredgej/Desktop/MICCAI_BraTS17_Data_Training/train/HGG/*/')\n",
    "# print(paths)\n",
    "\n",
    "import os\n",
    "HGG_dir_list = next(os.walk('./HGG/'))[1]\n",
    "print(len(HGG_dir_list))\n",
    "LGG_dir_list = next(os.walk('./LGG/'))[1]\n",
    "print(len(LGG_dir_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:05:37.233873Z",
     "start_time": "2018-06-19T22:05:37.228522Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "97\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# completelist = HGG_dir_list + LGG_dir_list\n",
    "\n",
    "completelist = list(survival_data.Brats17ID.copy())\n",
    "\n",
    "# print(completelist[0:4])\n",
    "np.random.shuffle(completelist) # shuffles in place\n",
    "# print(completelist[0:4])\n",
    "\n",
    "partition={}\n",
    "\n",
    "holdout_percentage=0.15\n",
    "partition['holdout']=completelist[0:int(len(completelist)*holdout_percentage)]\n",
    "trainlist=completelist[int(len(completelist)*holdout_percentage):len(completelist)]\n",
    "\n",
    "train_percentage=0.7\n",
    "partition['train']=trainlist[0:int(len(trainlist)*train_percentage)]\n",
    "partition['test']=trainlist[int(len(trainlist)*train_percentage):len(trainlist)]\n",
    "\n",
    "\n",
    "labels={}\n",
    "# HGG=0\n",
    "# LGG=1\n",
    "for directory in HGG_dir_list:\n",
    "    labels[directory]=0\n",
    "for directory in LGG_dir_list:\n",
    "    labels[directory]=1\n",
    "    \n",
    "print(len(partition['holdout']))\n",
    "print(len(partition['train']))\n",
    "print(len(partition['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(completelist)\n",
    "# len(survival_data.Brats17ID)\n",
    "# len(set.intersection(set(completelist),set(survival_data.Brats17ID)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crop_img function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T03:08:13.825621Z",
     "start_time": "2018-06-19T03:08:12.703423Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn.image.image import check_niimg\n",
    "from nilearn.image.image import _crop_img_to as crop_img_to\n",
    "\n",
    "\n",
    "def crop_img(img, rtol=1e-8, copy=True, return_slices=False):\n",
    "    \"\"\"Crops img as much as possible\n",
    "    Will crop img, removing as many zero entries as possible\n",
    "    without touching non-zero entries. Will leave one voxel of\n",
    "    zero padding around the obtained non-zero area in order to\n",
    "    avoid sampling issues later on.\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: Niimg-like object\n",
    "        See http://nilearn.github.io/manipulating_images/input_output.html\n",
    "        img to be cropped.\n",
    "    rtol: float\n",
    "        relative tolerance (with respect to maximal absolute\n",
    "        value of the image), under which values are considered\n",
    "        negligeable and thus croppable.\n",
    "    copy: boolean\n",
    "        Specifies whether cropped data is copied or not.\n",
    "    return_slices: boolean\n",
    "        If True, the slices that define the cropped image will be returned.\n",
    "    Returns\n",
    "    -------\n",
    "    cropped_img: image\n",
    "        Cropped version of the input image\n",
    "    \"\"\"\n",
    "\n",
    "    img = check_niimg(img)\n",
    "    data = img.get_data()\n",
    "    infinity_norm = max(-data.min(), data.max())\n",
    "    passes_threshold = np.logical_or(data < -rtol * infinity_norm,\n",
    "                                     data > rtol * infinity_norm)\n",
    "\n",
    "    if data.ndim == 4:\n",
    "        passes_threshold = np.any(passes_threshold, axis=-1)\n",
    "    coords = np.array(np.where(passes_threshold))\n",
    "    start = coords.min(axis=1)\n",
    "    end = coords.max(axis=1) + 1\n",
    "\n",
    "    # pad with one voxel to avoid resampling problems\n",
    "    start = np.maximum(start - 1, 0)\n",
    "    end = np.minimum(end + 1, data.shape[:3])\n",
    "\n",
    "    slices = [slice(s, e) for s, e in zip(start, end)]\n",
    "\n",
    "    if return_slices:\n",
    "        return slices\n",
    "\n",
    "    return crop_img_to(img, slices, copy=copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:12:14.451690Z",
     "start_time": "2018-06-16T16:12:14.441564Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import nibabel as nib\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=2, dim=(240,240,155), n_channels=4,\n",
    "                 n_classes=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y1, y2 = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, [y1, y2]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.n_channels, *self.dim))\n",
    "        y1 = np.empty((self.batch_size, 3, *self.dim))\n",
    "        y2 = np.empty(self.batch_size)\n",
    "\n",
    "        # Generate data\n",
    "        # Decode and load the data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            img1 = './data/' + ID + '_flair.nii.gz'\n",
    "            img2 = './data/' + ID + '_t1.nii.gz'\n",
    "            img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "            img4 = './data/' + ID + '_t2.nii.gz'\n",
    "            img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "            newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "            cropped = crop_img(newimage)         \n",
    "            img_array = np.array(cropped.dataobj)\n",
    "            z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "            padded_image = np.zeros((5,160,192,160))\n",
    "            padded_image[:z.shape[0],:z.shape[1],:z.shape[2],:z.shape[3]] = z\n",
    "\n",
    "            a,b,c,d,seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "            images = np.concatenate([a,b,c,d], axis=0)\n",
    "\n",
    "            # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "            # split the channels:\n",
    "            # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "            seg_mask_1 = np.zeros((1,160,192,160))\n",
    "            seg_mask_1[seg_mask.astype(int) == 1] = 1\n",
    "            seg_mask_2 = np.zeros((1,160,192,160))\n",
    "            seg_mask_2[seg_mask.astype(int) == 2] = 1\n",
    "            seg_mask_3 = np.zeros((1,160,192,160))\n",
    "            seg_mask_3[seg_mask.astype(int) == 4] = 1\n",
    "            seg_mask_3ch = np.concatenate([seg_mask_1,seg_mask_2,seg_mask_3], axis=0).astype(int)\n",
    "            \n",
    "            # 1) the \"enhancing tumor\" (ET), 2) the \"tumor core\" (TC), and 3) the \"whole tumor\" (WT) \n",
    "            # The ET is described by areas that show hyper-intensity in T1Gd when compared to T1, but also when compared to healthy white matter in T1Gd. The TC describes the bulk of the tumor, which is what is typically resected. The TC entails the ET, as well as the necrotic (fluid-filled) and the non-enhancing (solid) parts of the tumor. The appearance of the necrotic (NCR) and the non-enhancing (NET) tumor core is typically hypo-intense in T1-Gd when compared to T1. The WT describes the complete extent of the disease, as it entails the TC and the peritumoral edema (ED), which is typically depicted by hyper-intense signal in FLAIR.\n",
    "            # The labels in the provided data are: \n",
    "            # 1 for NCR & NET (necrotic (NCR) and the non-enhancing (NET) tumor core) = TC (\"tumor core\")\n",
    "            # 2 for ED (\"peritumoral edema\")\n",
    "            # 4 for ET (\"enhancing tumor\")\n",
    "            # 0 for everything else\n",
    "\n",
    "            X[i,] = images\n",
    "            y1[i,] = seg_mask_3ch\n",
    "#             y2[i,] = int(survival_data[survival_data.Brats17ID==ID].Survival) # list of the survival day values\n",
    "            y2[i,] = survival_data[survival_data.Brats17ID==ID].Survival.astype(int).values.item(0)\n",
    "            \n",
    "#         return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        return X, y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "# from my_classes import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T16:15:14.331Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:38: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:38: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(workers=4, validation_data=<__main__...., callbacks=[<keras.ca..., epochs=2, generator=<__main__....)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "97/97 [==============================] - 1323s 14s/step - loss: 39614.1012 - activation_block_loss: -0.0211 - survival_block_loss: 198070.6105 - activation_block_acc: 0.0842 - activation_block_weighted_dice_coefficient: 0.0211 - activation_block_dice_coefficient: 0.0212 - survival_block_acc: 0.0000e+00 - val_loss: 28528.1873 - val_activation_block_loss: -0.0250 - val_survival_block_loss: 142641.0602 - val_activation_block_acc: 0.0908 - val_activation_block_weighted_dice_coefficient: 0.0250 - val_activation_block_dice_coefficient: 0.0251 - val_survival_block_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "97/97 [==============================] - 1260s 13s/step - loss: 41016.4711 - activation_block_loss: -0.0222 - survival_block_loss: 205082.4639 - activation_block_acc: 0.0761 - activation_block_weighted_dice_coefficient: 0.0222 - activation_block_dice_coefficient: 0.0223 - survival_block_acc: 0.0000e+00 - val_loss: 29143.5786 - val_activation_block_loss: -0.0257 - val_survival_block_loss: 145718.0195 - val_activation_block_acc: 0.0520 - val_activation_block_weighted_dice_coefficient: 0.0257 - val_activation_block_dice_coefficient: 0.0257 - val_survival_block_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "\n",
    "# # Datasets\n",
    "# partition = # IDs\n",
    "# labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], **params)\n",
    "validation_generator = DataGenerator(partition['test'], **params)\n",
    "\n",
    "# # Design model\n",
    "# model = Sequential()\n",
    "# [...] # Architecture\n",
    "# model.compile()\n",
    "\n",
    "# Train model on dataset\n",
    "# model.fit_generator(generator=training_generator,\n",
    "#                     validation_data=validation_generator,\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=4)\n",
    "\n",
    "cb_1=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "cb_2=keras.callbacks.ModelCheckpoint(filepath=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# losses = {'activation_block': weighted_dice_coefficient_loss, 'survival_block': 'mean_squared_error'}\n",
    "# cb_1=keras.callbacks.EarlyStopping(monitor=losses, min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "# cb_2=keras.callbacks.ModelCheckpoint(filepath=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor=losses, verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "results = model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                   epochs=2, \n",
    "                   nb_worker=4,\n",
    "                   callbacks=[cb_1,cb_2])\n",
    "\n",
    "# results = model.fit_generator(generator=training_generator,\n",
    "#                     validation_data=validation_generator,\n",
    "#                    epochs=2, \n",
    "#                    nb_worker=4)\n",
    "# print(\"Test-Accuracy:\", np.mean(results.history[\"val_acc\"]))\n",
    "\n",
    "\n",
    "# model.fit_generator(\n",
    "#         generator=training_generator,\n",
    "#         samples_per_epoch=2,\n",
    "#         steps_per_epoch=2000,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         nb_worker=1,\n",
    "#         validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_block_acc': [0.08418684643837288, 0.07605262888240215],\n",
       " 'activation_block_dice_coefficient': [0.0211605962231448,\n",
       "  0.02230567293308829],\n",
       " 'activation_block_loss': [-0.021105371021963273, -0.02216169289217244],\n",
       " 'activation_block_weighted_dice_coefficient': [0.021105371021963273,\n",
       "  0.02216169289217244],\n",
       " 'loss': [39614.10124309776, 41016.47108887151],\n",
       " 'survival_block_acc': [0.0, 0.0],\n",
       " 'survival_block_loss': [198070.61052027438, 205082.46392527316],\n",
       " 'val_activation_block_acc': [0.0908030028942795, 0.0519779266434766],\n",
       " 'val_activation_block_dice_coefficient': [0.025079544619767972,\n",
       "  0.025657636897882356],\n",
       " 'val_activation_block_loss': [-0.02497291729031574, -0.025653085482883312],\n",
       " 'val_activation_block_weighted_dice_coefficient': [0.02497291729031574,\n",
       "  0.025653085482883312],\n",
       " 'val_loss': [28528.18727736246, 29143.57856241862],\n",
       " 'val_survival_block_acc': [0.0, 0.0],\n",
       " 'val_survival_block_loss': [142641.06021808443, 145718.01948274884]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "params = {'dim': (160,192,160),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 4,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Turned shuffle off so that we can match the values in the dictionary to the predictions. \n",
    "# This way we can compare the predictions side-by-side with the ground truth.\n",
    "\n",
    "validation_generator = DataGenerator(partition['holdout'], **params)\n",
    "\n",
    "prediction = model.predict_generator(generator=validation_generator)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 160, 192, 160)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # sanity check on the predictions:\n",
    "# len(prediction)\n",
    "# prediction[0].shape\n",
    "# np.unique(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory channel_split: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# ! mkdir to_categorical_try\n",
    "# ! mkdir channel_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump( partition, open( \"./channel_split/partition.pkl\", \"wb\" ) ) # this has the test/train ID matches\n",
    "\n",
    "# # # access the test list:\n",
    "# # testIDlist = partition['test']\n",
    "# # testIDlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(prediction)):\n",
    "#     pickle.dump( prediction[i], open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "# # pickle.dump( model, open( \"model.pkl\", \"wb\" ) )\n",
    "# model.save_weights('./channel_split/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T03:08:23.123674Z",
     "start_time": "2018-06-19T03:08:23.119560Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "partition = pickle.load(open( \"./channel_split/partition.pkl\", \"rb\" ) ) # this has the test/train ID matches\n",
    "\n",
    "# access the test list:\n",
    "testIDlist = partition['test']\n",
    "# testIDlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T22:17:03.562719Z",
     "start_time": "2018-06-18T22:17:03.560118Z"
    }
   },
   "source": [
    "### Write images to .tif:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tifffile import imsave\n",
    "for i in range(len(prediction)):\n",
    "    imarray = pickle.load(open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"rb\" ) )\n",
    "\n",
    "    imarray[]\n",
    "    imarray *= 255.0/imarray.max()\n",
    "    print(np.unique())\n",
    "    \n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"prediction.tif\", imarray)\n",
    "\n",
    "    # make ground truth \n",
    "    ID = testIDlist[i]\n",
    "    img1 = './data/' + ID + '_flair.nii.gz'\n",
    "    img2 = './data/' + ID + '_t1.nii.gz'\n",
    "    img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "    img4 = './data/' + ID + '_t2.nii.gz'\n",
    "    img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "    newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "    cropped = crop_img(newimage)         \n",
    "    img_array = np.array(cropped.dataobj)\n",
    "    z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "    padded_image = np.zeros((5,160,192,160))\n",
    "    padded_image[:z.shape[0],:z.shape[1],:z.shape[2],:z.shape[3]] = z\n",
    "\n",
    "    a,b,c,d,seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "    images = np.concatenate([a,b,c,d], axis=0)\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", images)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T22:45:15.378978Z",
     "start_time": "2018-06-18T22:45:14.073957Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[  0 255]\n",
      "(3, 160, 192, 160)\n",
      "[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "   42   43   44   45   46   47   48   49   50   51   52   53   54   55\n",
      "   56   57   58   59   60   61   62   63   64   65   66   67   68   69\n",
      "   70   71   72   73   74   75   76   77   78   79   80   81   82   83\n",
      "   84   85   86   87   88   89   90   91   92   93   94   95   96   97\n",
      "   98   99  100  101  102  103  104  105  106  107  108  109  110  111\n",
      "  112  113  114  115  116  117  118  119  120  121  122  123  124  125\n",
      "  126  127  128  129  130  131  132  133  134  135  136  137  138  139\n",
      "  140  141  142  143  144  145  146  147  148  149  150  151  152  153\n",
      "  154  155  156  157  158  159  160  161  162  163  164  165  166  167\n",
      "  168  169  170  171  172  173  174  175  176  177  178  179  180  181\n",
      "  182  183  184  185  186  187  188  189  190  191  192  193  194  195\n",
      "  196  197  198  199  200  201  202  203  204  205  206  207  208  209\n",
      "  210  211  212  213  214  215  216  217  218  219  220  221  222  223\n",
      "  224  225  226  227  228  229  230  231  232  233  234  235  236  237\n",
      "  238  239  240  241  242  243  244  245  246  247  248  249  250  251\n",
      "  252  253  254  255  256  257  258  259  260  261  262  263  264  265\n",
      "  266  267  268  269  270  271  272  273  274  275  276  277  278  279\n",
      "  280  281  282  283  284  285  286  287  288  289  290  291  292  293\n",
      "  294  295  296  297  298  299  300  301  302  303  304  305  306  307\n",
      "  308  309  310  311  312  313  314  315  316  317  318  319  320  321\n",
      "  322  323  324  325  326  327  328  329  330  331  332  333  334  335\n",
      "  336  337  338  339  340  341  342  343  344  345  346  347  348  349\n",
      "  350  351  352  353  354  355  356  357  358  359  360  361  362  363\n",
      "  364  365  366  367  368  369  370  371  372  373  374  375  376  377\n",
      "  378  379  380  381  382  383  384  385  386  387  388  389  390  391\n",
      "  392  393  394  395  396  397  398  399  400  401  402  403  404  405\n",
      "  406  407  408  409  410  411  412  413  414  415  416  417  418  419\n",
      "  420  421  422  423  424  425  426  427  428  429  430  431  432  433\n",
      "  434  435  436  437  438  439  440  441  442  443  444  445  446  447\n",
      "  448  449  450  451  452  453  454  455  456  457  458  459  460  461\n",
      "  462  463  464  465  466  467  468  469  470  471  472  473  474  475\n",
      "  476  477  478  479  480  481  482  483  484  485  486  487  488  489\n",
      "  490  491  492  493  494  495  496  497  498  499  500  501  502  503\n",
      "  504  505  506  507  508  509  510  511  512  513  514  515  516  517\n",
      "  518  519  520  521  522  523  524  525  526  527  528  529  530  531\n",
      "  532  533  534  535  536  537  538  539  540  541  542  543  544  545\n",
      "  546  547  548  549  550  551  552  553  554  555  556  557  558  559\n",
      "  560  561  562  563  564  565  566  567  568  569  570  571  572  573\n",
      "  574  575  576  577  578  579  580  581  582  583  584  585  586  587\n",
      "  588  589  590  591  592  593  594  595  596  597  598  599  600  601\n",
      "  602  603  604  605  606  607  608  609  610  611  612  613  614  615\n",
      "  616  617  618  619  620  621  622  623  624  625  626  627  628  629\n",
      "  630  631  632  633  634  635  636  637  638  639  640  641  642  643\n",
      "  644  645  646  647  648  649  650  651  652  653  654  655  656  657\n",
      "  658  659  660  661  662  663  664  665  666  667  668  669  670  671\n",
      "  672  673  674  675  676  677  678  680  681  682  683  684  685  686\n",
      "  687  688  689  690  691  692  693  694  695  696  697  700  701  702\n",
      "  703  704  705  706  707  708  709  710  711  712  713  715  716  718\n",
      "  719  720  722  723  724  725  726  727  728  729  730  731  734  735\n",
      "  736  737  738  739  740  742  744  745  749  752  753  755  756  757\n",
      "  758  760  768  770  771  772  775  788  790  793  798  865  877  879\n",
      "  890  891  945 1030 1086]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 180\n",
      " 181 185 186 187 203 205 206 208 209 221 241 255]\n",
      "(155, 1, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "import nibabel as nib\n",
    "\n",
    "i = 0\n",
    "\n",
    "imarray = pickle.load(open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"rb\" ) )\n",
    "# threshold the channels (for prediction):\n",
    "prediction_thresh = copy.deepcopy(imarray)\n",
    "prediction_thresh[prediction_thresh < 0.5] = 0.\n",
    "prediction_thresh[prediction_thresh >= 0.5] = 1.\n",
    "prediction_thresh = prediction_thresh\n",
    "print(np.unique(prediction_thresh))\n",
    "prediction_thresh *= 255.0/prediction_thresh.max() # convert to 8-bit pixel values\n",
    "prediction_thresh = prediction_thresh.astype(int)\n",
    "print(np.unique(prediction_thresh))\n",
    "print(prediction_thresh.shape)\n",
    "\n",
    "ID = testIDlist[i]\n",
    "img1 = './data/' + ID + '_flair.nii.gz'\n",
    "flairimg = nib.load(img1)\n",
    "flairimg = np.array(flairimg.dataobj)\n",
    "flairimg = np.expand_dims(flairimg, axis=0)\n",
    "flairimg = np.rollaxis(flairimg, 3, 0)\n",
    "print(np.unique(flairimg))\n",
    "flairimg = flairimg.astype(float)\n",
    "flairimg *= 255.0/flairimg.max() # convert to 8-bit pixel values\n",
    "flairimg = flairimg.astype(int)\n",
    "print(np.unique(flairimg))\n",
    "print(flairimg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making ground truth .tiff files: \n",
    "- Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T03:45:32.961094Z",
     "start_time": "2018-06-19T03:45:29.517419Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image: 0\n",
      "current image: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import nibabel as nib\n",
    "\n",
    "from tifffile import imsave\n",
    "from libtiff import TIFF\n",
    "\n",
    "from skimage.io._plugins import freeimage_plugin as fi\n",
    "\n",
    "# import javabridge\n",
    "# import bioformats\n",
    "# javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "# your program goes here\n",
    "\n",
    "\n",
    "# ID = testIDlist[i]\n",
    "# for i in range(len(testIDlist)):\n",
    "for i in range(2):\n",
    "\n",
    "    print(\"current image:\", i)\n",
    "\n",
    "    ID = testIDlist[i]\n",
    "    img1 = './data/' + ID + '_flair.nii.gz'\n",
    "    img2 = './data/' + ID + '_t1.nii.gz'\n",
    "    img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "    img4 = './data/' + ID + '_t2.nii.gz'\n",
    "    img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "    newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "    cropped = crop_img(newimage)\n",
    "    img_array = np.array(cropped.dataobj)\n",
    "    z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "    padded_image = np.zeros((5, 160, 192, 160))\n",
    "    padded_image[:z.shape[0], :z.shape[1], :z.shape[2], :z.shape[3]] = z\n",
    "\n",
    "    a, b, c, d, seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "    images = np.concatenate([a, b, c, d], axis=0)\n",
    "\n",
    "    # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "    # split the channels:\n",
    "    # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "    seg_mask_1 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_1[seg_mask.astype(int) > 0] = 1\n",
    "    seg_mask_2 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_2[seg_mask.astype(int) > 1] = 1\n",
    "    seg_mask_3 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_3[seg_mask.astype(int) > 2] = 1\n",
    "    seg_mask_3ch = np.concatenate(\n",
    "        [seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype(int)\n",
    "\n",
    "    # def scale_image(image_array):\n",
    "    #     image_array = image_array.astype(float)\n",
    "    #     image_array *= 255.0/image_array.max() # convert to 8-bit pixel values\n",
    "    #     image_array = image_array.astype(int)\n",
    "    #     return image_array\n",
    "\n",
    "    # img_array_list = [a,seg_mask_1,seg_mask_2,seg_mask_3]\n",
    "    # for img_array in img_array_list:\n",
    "    #     img_array = scale_image(img_array)\n",
    "\n",
    "    a = a.astype(float)\n",
    "    a *= 255.0/a.max()  # convert to 8-bit pixel values\n",
    "    a = np.rollaxis(a, 0, 2)\n",
    "    a = a.astype('uint8')\n",
    "#     print(\"unique flair values:\", np.unique(a))\n",
    "\n",
    "    seg_mask_1 = seg_mask_1.astype(float)\n",
    "    seg_mask_1 *= 255.0/seg_mask_1.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_1 = np.rollaxis(seg_mask_1, 0, 2)\n",
    "    seg_mask_1 = seg_mask_1.astype('uint8')\n",
    "#     print(\"unique segment mask values:\", np.unique(seg_mask_1))\n",
    "\n",
    "    seg_mask_2 = seg_mask_2.astype(float)\n",
    "    seg_mask_2 *= 255.0/seg_mask_2.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_2 = np.rollaxis(seg_mask_2, 0, 2)\n",
    "    seg_mask_2 = seg_mask_2.astype('uint8')\n",
    "\n",
    "    seg_mask_3 = seg_mask_3.astype(float)\n",
    "    seg_mask_3 *= 255.0/seg_mask_3.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_3 = np.rollaxis(seg_mask_3, 0, 2)\n",
    "    seg_mask_3 = seg_mask_3.astype('uint8')\n",
    "\n",
    "#     ground_truth = np.concatenate(\n",
    "#         [a, seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype('uint8')\n",
    "\n",
    "#     print(\"unique flair + segment mask values:\", np.unique(ground_truth))\n",
    "    # shape.ground_truth\n",
    "    # flairimg = flairimg.astype(float)\n",
    "    # flairimg *= 255.0/flairimg.max() # convert to 8-bit pixel values\n",
    "    # flairimg = flairimg.astype(int)\n",
    "    # print(np.unique(flairimg))\n",
    "#     print(\"final image shape:\", ground_truth.shape)\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", ground_truth, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"flair.tif\", a, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_1.tif\", seg_mask_1, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_2.tif\", seg_mask_2, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_3.tif\", seg_mask_3, 'imagej')\n",
    "\n",
    "#     tiff = TIFF.open(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", mode='w')\n",
    "#     tiff.write_image(ground_truth)\n",
    "#     tiff.close()\n",
    "#     fi.write_multipage(ground_truth, \"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\")\n",
    "#     bioformats.write_image(pathname=\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", \n",
    "#                            pixels=ground_truth, \n",
    "#                            pixel_type=u'uint8',\n",
    "#                            size_c=4, size_z=160, size_t=1,\n",
    "#                            channel_names=None)\n",
    "\n",
    "# javabridge.kill_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T04:25:05.674829Z",
     "start_time": "2018-06-19T04:25:00.697594Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image: 0\n",
      "[0. 1.]\n",
      "[  0 255]\n",
      "(3, 192, 160, 160)\n",
      "current image: 1\n",
      "[0. 1.]\n",
      "[  0 255]\n",
      "(3, 192, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import nibabel as nib\n",
    "\n",
    "from tifffile import imsave\n",
    "from libtiff import TIFF\n",
    "\n",
    "from skimage.io._plugins import freeimage_plugin as fi\n",
    "\n",
    "# import javabridge\n",
    "# import bioformats\n",
    "# javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "# your program goes here\n",
    "\n",
    "\n",
    "# ID = testIDlist[i]\n",
    "# for i in range(len(testIDlist)):\n",
    "for i in range(2):\n",
    "\n",
    "    print(\"current image:\", i)\n",
    "\n",
    "    ID = testIDlist[i]\n",
    "    img1 = './data/' + ID + '_flair.nii.gz'\n",
    "    img2 = './data/' + ID + '_t1.nii.gz'\n",
    "    img3 = './data/' + ID + '_t1ce.nii.gz'\n",
    "    img4 = './data/' + ID + '_t2.nii.gz'\n",
    "    img5 = './data/' + ID + '_seg.nii.gz'\n",
    "\n",
    "    newimage = nib.concat_images([img1, img2, img3, img4, img5])\n",
    "    cropped = crop_img(newimage)\n",
    "    img_array = np.array(cropped.dataobj)\n",
    "    z = np.rollaxis(img_array, 3, 0)\n",
    "\n",
    "    padded_image = np.zeros((5, 160, 192, 160))\n",
    "    padded_image[:z.shape[0], :z.shape[1], :z.shape[2], :z.shape[3]] = z\n",
    "\n",
    "    a, b, c, d, seg_mask = np.split(padded_image, 5, axis=0)\n",
    "\n",
    "    images = np.concatenate([a, b, c, d], axis=0)\n",
    "\n",
    "    # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "    # split the channels:\n",
    "    # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "    seg_mask_1 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_1[seg_mask.astype(int) > 0] = 1\n",
    "    seg_mask_2 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_2[seg_mask.astype(int) > 1] = 1\n",
    "    seg_mask_3 = np.zeros((1, 160, 192, 160))\n",
    "    seg_mask_3[seg_mask.astype(int) > 2] = 1\n",
    "    seg_mask_3ch = np.concatenate(\n",
    "        [seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype(int)\n",
    "\n",
    "    # def scale_image(image_array):\n",
    "    #     image_array = image_array.astype(float)\n",
    "    #     image_array *= 255.0/image_array.max() # convert to 8-bit pixel values\n",
    "    #     image_array = image_array.astype(int)\n",
    "    #     return image_array\n",
    "\n",
    "    # img_array_list = [a,seg_mask_1,seg_mask_2,seg_mask_3]\n",
    "    # for img_array in img_array_list:\n",
    "    #     img_array = scale_image(img_array)\n",
    "\n",
    "    a = a.astype(float)\n",
    "    a *= 255.0/a.max()  # convert to 8-bit pixel values\n",
    "    a = np.rollaxis(a, 0, 2) # cxyz -> xycz for imagej\n",
    "    a = np.rollaxis(a, 0, 3) # switching x and z\n",
    "    a = a.astype('uint8')\n",
    "#     print(\"unique flair values:\", np.unique(a))\n",
    "\n",
    "    seg_mask_1 = seg_mask_1.astype(float)\n",
    "    seg_mask_1 *= 255.0/seg_mask_1.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_1 = np.rollaxis(seg_mask_1, 0, 2) # cxyz -> xycz for imagej\n",
    "    seg_mask_1 = np.rollaxis(seg_mask_1, 0, 3) # switching x and z\n",
    "    seg_mask_1 = seg_mask_1.astype('uint8')\n",
    "#     print(\"unique segment mask values:\", np.unique(seg_mask_1))\n",
    "\n",
    "    seg_mask_2 = seg_mask_2.astype(float)\n",
    "    seg_mask_2 *= 255.0/seg_mask_2.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_2 = np.rollaxis(seg_mask_2, 0, 2) # cxyz -> xycz for imagej\n",
    "    seg_mask_2 = np.rollaxis(seg_mask_2, 0, 3) # switching x and z\n",
    "    seg_mask_2 = seg_mask_2.astype('uint8')\n",
    "\n",
    "    seg_mask_3 = seg_mask_3.astype(float)\n",
    "    seg_mask_3 *= 255.0/seg_mask_3.max()  # convert to 8-bit pixel values\n",
    "    seg_mask_3 = np.rollaxis(seg_mask_3, 0, 2) # cxyz -> xycz for imagej\n",
    "    seg_mask_3 = np.rollaxis(seg_mask_3, 0, 3) # switching x and z\n",
    "    seg_mask_3 = seg_mask_3.astype('uint8')\n",
    "\n",
    "#     ground_truth = np.concatenate(\n",
    "#         [a, seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype('uint8')\n",
    "\n",
    "#     print(\"unique flair + segment mask values:\", np.unique(ground_truth))\n",
    "    # shape.ground_truth\n",
    "    # flairimg = flairimg.astype(float)\n",
    "    # flairimg *= 255.0/flairimg.max() # convert to 8-bit pixel values\n",
    "    # flairimg = flairimg.astype(int)\n",
    "    # print(np.unique(flairimg))\n",
    "#     print(\"final image shape:\", ground_truth.shape)\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth.tif\", ground_truth, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_flair.tif\", a, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_ground_truth_1.tif\", seg_mask_1, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_ground_truth_2.tif\", seg_mask_2, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_ground_truth_3.tif\", seg_mask_3, 'imagej')\n",
    "\n",
    "    imarray = pickle.load(open( \"./channel_split/prediction_\"+str(i)+\".pkl\", \"rb\" ) )\n",
    "\n",
    "    prediction_thresh = copy.deepcopy(imarray)\n",
    "    prediction_thresh[prediction_thresh < 0.5] = 0.\n",
    "    prediction_thresh[prediction_thresh >= 0.5] = 1.\n",
    "    prediction_thresh = prediction_thresh\n",
    "    print(np.unique(prediction_thresh))\n",
    "    prediction_thresh *= 255.0/prediction_thresh.max() # convert to 8-bit pixel values\n",
    "    prediction_thresh = prediction_thresh.astype('uint8')\n",
    "    prediction_thresh = np.rollaxis(prediction_thresh, 1, 3) # switching x and z; c will be taken care of in split\n",
    "    print(np.unique(prediction_thresh))\n",
    "    print(prediction_thresh.shape)\n",
    "\n",
    "    pred1, pred2, pred3 = np.split(prediction_thresh, 3, axis=0)\n",
    "\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_predicted_1.tif\", pred1, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_predicted_2.tif\", pred2, 'imagej')\n",
    "    imsave(\"./channel_split/\"+testIDlist[i]+\"_predicted_3.tif\", pred3, 'imagej')\n",
    "\n",
    "    # print(\"images shape:\", images.shape, \"images values:\", np.unique(images.astype(int)))\n",
    "\n",
    "    # split the channels:\n",
    "    # seg_mask_1 = copy.deepcopy(seg_mask.astype(int))\n",
    "\n",
    "\n",
    "    #     seg_mask_3ch = np.concatenate(\n",
    "#         [seg_mask_1, seg_mask_2, seg_mask_3], axis=0).astype(int)\n",
    "\n",
    "#     imarray *= 255.0/imarray.max()\n",
    "\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_1.tif\", seg_mask_1, 'imagej')\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_2.tif\", seg_mask_2, 'imagej')\n",
    "#     imsave(\"./channel_split/\"+testIDlist[i]+\"ground_truth_3.tif\", seg_mask_3, 'imagej')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
